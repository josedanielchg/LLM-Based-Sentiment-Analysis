\section{Conclusion}

Cette section vise à établir un ensemble de conclusions concernant la mise en œuvre de méthodes de classification de sentiment pour des textes courts en anglais. Tout d’abord, il est important de souligner l’analyse réalisée lors de la phase préliminaire du jeu de données et de ses principales caractéristiques. À partir de cette analyse, on observe que, compte tenu des informations d’entraînement disponibles, la variable principale d’intérêt pour l’entraînement de ce type de classifieur est sans aucun doute le texte traité après suppression des stopwords, principalement parce que la distribution des classes par rapport aux autres variables incluses dans le jeu de données reste soit constante, comme dans le cas des tranches d’âge, soit pourrait impliquer un risque accru de mémoriser des motifs incorrects, puisque les éléments de chaque classe au sein de la catégorie non considérée ne sont pas représentatifs de la compilation globale, comme dans le cas de la variable pays.

En ce qui concerne l’entraînement des modèles classiques d’apprentissage automatique, les résultats de classification atteignent de hautes performances, principalement grâce à la prise en compte de multiples pipelines de modèles combinant un vectoriseur avec le classifieur et les variations correspondantes de leurs grilles d’hyperparamètres. Cela conduit à un total de 956 modèles entraînés, parmi lesquels les configurations les plus performantes sont sélectionnées. De plus, à travers les trois types de représentations, les meilleurs résultats sont obtenus pour SVM, la Régression Logistique et la Forêt Aléatoire, avec de légers avantages en termes de F1 et d’accuracy pour la Forêt Aléatoire dans la plupart des cas. Néanmoins, des modèles tels que la Régression Logistique et le SVM sont plus intelligibles et interprétables ; par conséquent, et en considérant que les différences de performance entre la Forêt Aléatoire et la Régression Logistique/SVM ne sont pas suffisamment significatives pour indiquer que la Forêt Aléatoire est la meilleure option de classification pour des modèles NLP, il est important de noter que, malgré ses métriques légèrement meilleures, la Forêt Aléatoire implique un coût d’entraînement substantiellement plus élevé en temps de calcul et en utilisation de ressources.

Bien que, dans le cas de l’entraînement de modèles classiques, la pertinence de la méthode de vectorisation et son choix soient abordés et référencés, l’algorithme d’entraînement avec recherche sur grille permet d’atténuer cet effet lors de la sélection d’un pipeline, puisque la recherche sur les paramètres du vectoriseur est incluse dans la procédure de recherche sur grille. Cependant, dans le cas des MLP, le plus petit nombre de candidats, l’influence de chaque type de vectorisation sur la structure du réseau, et l’incorporation d’embeddings BERT figés avant l’entraînement du MLP amènent la discussion à considérer non seulement le meilleur modèle, mais plutôt le pipeline le plus performant, incluant à la fois la vectorisation et la classification.

Lors de l’analyse des résultats sur test des MLP entraînés avec des entrées TF--IDF au niveau des caractères, l’écart entre les performances d’entraînement et de test indique que le modèle possède une forte capacité d’ajustement et, par conséquent, un très haut risque de surentraînement ; des changements dans l’architecture du réseau, principalement en termes de largeur des couches et de méthodes de régularisation, compte tenu de la matrice creuse compressée qui entre dans le MLP, ne produisent pas toujours des améliorations proportionnelles sur l’ensemble de test parce que le risque de surentraînement augmente. En revanche, l’utilisation d’embeddings BERT figés, bien qu’elle montre des performances attendues avec moins de paramètres que les modèles TF--IDF au niveau des caractères sur les données de test, bénéficie de la nature dense de la matrice d’entrée et de la grande différence de complexité du réseau par rapport aux données d’entraînement. Cela fait apparaître les structures plus simples mises en œuvre avec ce type de vectorisation comme une stratégie conservatrice d’un intérêt significatif, comme dans le cas d’une seule couche de décision pour classifier les vecteurs d’information produits par BERT, tel que le modèle baseline. En effet, dans les modèles qui emploient ce type de vectorisation, l’augmentation de la profondeur et de la complexité globale du réseau peut être associée à une dégradation des performances sur les données de test, précisément parce que, compte tenu des caractéristiques de BERT et de la forte densité d’information qu’il fournit, la structure du réseau et le nombre de paramètres requis pour la classification peuvent rester simples.

Après avoir achevé l’entraînement des modèles MLP, les modèles classiques d’apprentissage automatique, conjointement avec la vectorisation TF--IDF au niveau des caractères, conservent de meilleures métriques de performance que les modèles MLP, y compris ceux qui utilisent des embeddings BERT pour la vectorisation, pour deux raisons principales. La première est la rigueur déjà mentionnée de la recherche d’hyperparamètres dans les modèles classiques d’apprentissage automatique. La seconde est que, pour le modèle MLP avec embeddings BERT, il reste une marge d’amélioration, en particulier pour la structure plus conservatrice qui montre de meilleures performances et un risque plus faible de surentraînement ; cette amélioration est rendue possible par la possibilité de réaliser un fine-tuning avec LoRA, qui permet au processus de vectorisation de s’adapter au domaine spécifique du jeu de données d’entraînement. Les résultats obtenus montrent que, parmi tous les modèles employés, le MLP à embeddings BERT avec fine-tuning LoRA atteint de loin les meilleures performances en termes de F1 et d’accuracy, et constitue donc une structure hautement recommandée pour développer des modèles de classification de textes courts basés sur la polarité ou le sentiment.
