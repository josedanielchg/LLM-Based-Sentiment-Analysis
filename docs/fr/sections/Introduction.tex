\section{Introduction}

L’analyse de sentiment de textes courts devient fondamentalement importante lorsque les perceptions sont considérées comme un actif informationnel critique pour les propriétaires de produits et de services \cite{b1}. Ceci est particulièrement pertinent dans le développement de systèmes guidés par les émotions, qui peuvent fournir des informations significatives afin d’améliorer l’expérience utilisateur ou client. Par exemple, ces informations peuvent conduire à des ajustements des stratégies de support client ou à des campagnes marketing plus ciblées \cite{b2}. En tant qu’entrée conceptuelle pour de telles améliorations, des systèmes de recherche ou des approches d’analyse de sentiment peuvent être adaptés afin de se concentrer sur les émotions exprimées par la population cible. Dans ce contexte, les réseaux sociaux—and plus spécifiquement des messages courts tels que des tweets et des commentaires sur des plateformes multimédias—figurent parmi les sources les plus couramment utilisées pour conduire ce type d’analyse.

Ce projet se concentre sur l’analyse automatique de sentiment de textes courts en anglais. Tout d’abord, une phase exploratoire est menée au cours de laquelle le contenu du jeu de données est prétraité, et une analyse préliminaire de l’information est réalisée à l’aide de méthodes traditionnelles d’apprentissage automatique. Ensuite, l’étape de classification est effectuée avec des classifieurs standards tels que Naive Bayes, la Régression Logistique et le SVM linéaire, en utilisant plusieurs schémas de représentation du texte, incluant bag-of-words, TF--IDF au niveau des mots et TF--IDF au niveau des caractères. La performance des modèles est rapportée à l’aide de l’accuracy, du macro-F1 et de métriques complémentaires afin d’assurer une comparaison équitable.

Ensuite, un perceptron multicouche (MLP) entraîné sur du texte vectorisé est évalué, et une alternative basée sur des embeddings BERT est étudiée afin de capturer la sémantique contextuelle. À cette fin, la performance des modèles MLP construits pour chaque approche de vectorisation est comparée à travers quatre architectures de réseau, chacune adaptée à la quantité d’information fournie par le vectoriseur correspondant ou par BERT, et orientée vers une classification finale à trois classes. De plus, une profondeur appropriée est définie en fonction du niveau de détail dans la représentation d’entrée afin de réduire le surapprentissage sur les données d’entraînement. Des couches de dropout sont également incorporées entre les couches cachées afin de contrôler davantage le surapprentissage et le surentraînement.

Enfin, afin d’améliorer la classification des messages, des stratégies basées sur des modèles de langage de grande taille (LLMs) ont été évaluées en utilisant la version API du modèle Gemma 3-4b-it (Gemini) pour comparer sa performance en tant que classifieur de textes courts aux modèles précédemment entraînés. De plus, LoRA a été utilisé pour réaliser un fine-tuning efficace de transformers basés sur BERT \cite{b3}.
