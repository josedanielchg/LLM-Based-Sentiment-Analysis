\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\citation{b1}
\citation{b2}
\citation{b3}
\citation{b4}
\babel@aux{french}{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Q0-Analyse du jeu de données avec différents modèles classiques d’apprentissage automatique}{1}{}\protected@file@percent }
\citation{b5}
\citation{b5}
\citation{b5}
\citation{b6}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Analyse exploratoire des données (EDA)}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Distribution des sentiments dans le jeu de données d’entraînement.}}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:q0-eda}{{1}{2}{}{}{}}
\newlabel{eq:tfidf}{{1}{2}{}{}{}}
\newlabel{eq:idf}{{2}{2}{}{}{}}
\newlabel{eq:l2norm}{{3}{2}{}{}{}}
\newlabel{fig:q0-bow-uni}{{2a}{3}{}{}{}}
\newlabel{sub@fig:q0-bow-uni}{{(a)}{a}}
\newlabel{fig:q0-bow-bi}{{2b}{3}{}{}{}}
\newlabel{sub@fig:q0-bow-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Top 20 n-gramas avec BoW.}}{3}{}\protected@file@percent }
\newlabel{fig:q0-bow}{{2}{3}{}{}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{3}{}\protected@file@percent }
\newlabel{fig:q0-tfidf-uni}{{3a}{3}{}{}{}}
\newlabel{sub@fig:q0-tfidf-uni}{{(a)}{a}}
\newlabel{fig:q0-tfidf-bi}{{3b}{3}{}{}{}}
\newlabel{sub@fig:q0-tfidf-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top 20 n-gramas avec TF--IDF.}}{3}{}\protected@file@percent }
\newlabel{fig:q0-tfidf}{{3}{3}{}{}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbu}{{4a}{3}{}{}{}}
\newlabel{sub@fig:q0-sbu}{{(a)}{a}}
\newlabel{fig:q0-sbtt}{{4b}{3}{}{}{}}
\newlabel{sub@fig:q0-sbtt}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Distribution comparative des sentiments par catégorie, stratifiée par utilisateur et type de tweet}}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbuubtt}{{4}{3}{}{}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Sentiments by User}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Sentiments by type of tweet}}}{3}{}\protected@file@percent }
\citation{b7}
\citation{b8}
\citation{b9}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution des sentiments dans les 10 principaux pays.}}{4}{}\protected@file@percent }
\newlabel{fig:q0-dcountry}{{5}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Distribution du nombre de mots par sentiment}}{4}{}\protected@file@percent }
\newlabel{fig:q0-wordcount}{{6}{4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Entraînement de modèles classiques}{4}{}\protected@file@percent }
\citation{b11}
\citation{b12}
\@writefile{toc}{\contentsline {section}{\numberline {III}Q1-Classification avec des modèles classiques et analyse des performances}{5}{}\protected@file@percent }
\newlabel{sec:q1}{{III}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Temps d’entraînement}{5}{}\protected@file@percent }
\newlabel{subsec:q1-time}{{\mbox  {III-A}}{5}{}{}{}}
\newlabel{subsubsec:q1-ttotal}{{\mbox  {III-A}1}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}1}Estimation du temps total (calcul séquentiel)}{5}{}\protected@file@percent }
\newlabel{eq:q1-e1}{{4}{5}{}{}{}}
\newlabel{subsubsec:q1-twall}{{\mbox  {III-A}2}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}2}Temps réel (wall-clock) avec parallélisation}{5}{}\protected@file@percent }
\newlabel{eq:q1-e2}{{5}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Performance sur l’ensemble de test}{6}{}\protected@file@percent }
\newlabel{subsec:q1-test}{{\mbox  {III-B}}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Comparaison sur test --- Macro-F1 (teinte = vectorisation).}}{6}{}\protected@file@percent }
\newlabel{fig:q1-f1}{{7}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparaison sur test --- Macro-Recall (teinte = vectorisation).}}{6}{}\protected@file@percent }
\newlabel{fig:q1-f2}{{8}{6}{}{}{}}
\newlabel{subsubsec:q1-vectorization}{{\mbox  {III-B}1}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}1}Impact de la méthode de vectorisation}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Comparaison sur test --- Accuracy (teinte = vectorisation).}}{6}{}\protected@file@percent }
\newlabel{fig:q1-f3}{{9}{6}{}{}{}}
\newlabel{subsubsec:q1-tradeoffs}{{\mbox  {III-B}2}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}2}Comparaison des modèles et compromis}{6}{}\protected@file@percent }
\newlabel{subsubsec:q1-cm}{{\mbox  {III-B}3}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}3}Analyse de la matrice de confusion (TF--IDF char)}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Matrice de confusion de \texttt  {best\_\_tfidf\_char\_\_svm}.}}{7}{}\protected@file@percent }
\newlabel{fig:q1-cm-svm}{{10}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Matrice de confusion de \texttt  {best\_\_tfidf\_char\_\_lr}.}}{7}{}\protected@file@percent }
\newlabel{fig:q1-cm-lr}{{11}{7}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3a}Motif général : la classe ``neutre'' est la principale source d’ambiguïté.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3b}Bon signe : faible confusion directe entre ``négatif'' et ``positif''.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3c}Différences subtiles entre SVM et Régression Logistique.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Top-20 et Bottom-20 n-grammes de caractères par classe (LR vs.\ SVM)}{7}{}\protected@file@percent }
\newlabel{subsec:q1-ngrams}{{\mbox  {III-C}}{7}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Classe positive}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Classe positive : Top-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-top}{{12}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Classe positive : Top-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-top}{{13}{8}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Classe négative}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Classe positive : Bottom-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-bottom}{{14}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Classe positive : Bottom-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-bottom}{{15}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Classe négative : Top-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-top}{{16}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Classe négative : Top-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{9}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-top}{{17}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Classe négative : Bottom-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{9}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-bottom}{{18}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}3}Classe neutre}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Synthèse et considérations pratiques}{9}{}\protected@file@percent }
\newlabel{subsec:q1-synthesis}{{\mbox  {III-D}}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Classe négative : Bottom-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{9}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-bottom}{{19}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Classe neutre : Top-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-top}{{20}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Classe neutre : Top-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-top}{{21}{9}{}{}{}}
\citation{b13}
\citation{b14}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Classe neutre : Bottom-20 n-grammes de caractères (Régression Logistique) sous TF--IDF char (\texttt  {char\_wb}).}}{10}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-bottom}{{22}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Classe neutre : Bottom-20 n-grammes de caractères (Linear SVM) sous TF--IDF char (\texttt  {char\_wb}).}}{10}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-bottom}{{23}{10}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Q2-Architectures MLP pour la classification de sentiment de textes courts}{10}{}\protected@file@percent }
\citation{b15}
\citation{b16}
\citation{b17}
\@writefile{toc}{\contentsline {section}{\numberline {V}Q3-Analyse comparative des performances des MLP et implications pour la sélection de la baseline}{13}{}\protected@file@percent }
\newlabel{sec:q3}{{V}{13}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Analyse préliminaire des performances des MLP (Q2)}{13}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-prelim}{{\mbox  {V-A}}{13}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Comparaison des performances MLP sur test --- Macro-F1 (teinte = famille de représentation).}}{13}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-f1}{{24}{13}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Comparaison des performances MLP sur test --- Macro-Recall (teinte = famille de représentation).}}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-recall}{{25}{14}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Comparaison des performances MLP sur test --- Accuracy (teinte = famille de représentation).}}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-acc}{{26}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Comparaison entre familles de représentations MLP (qualité prédictive)}{14}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-families}{{\mbox  {V-B}}{14}{}{}{}}
\newlabel{subsubsec:q3-char-tfidf}{{\mbox  {V-B}1}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}1}Char TF--IDF (meilleure famille en qualité prédictive)}{14}{}\protected@file@percent }
\newlabel{subsubsec:q3-bow-word}{{\mbox  {V-B}2}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}2}BoW et Word TF--IDF (performance intermédiaire, BoW légèrement supérieur)}{14}{}\protected@file@percent }
\newlabel{subsubsec:q3-bert}{{\mbox  {V-B}3}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}3}BERT (compétitif, mais non supérieur à Char TF--IDF sous ce régime)}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Comparaison des performances MLP sur l’entraînement --- Accuracy (teinte = famille de représentation).}}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-acc}{{27}{15}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Comparaison des performances MLP sur l’entraînement --- Macro-F1 (teinte = famille de représentation).}}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-f1}{{28}{15}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Comparaison des performances MLP sur l’entraînement --- Macro-Recall (teinte = famille de représentation).}}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-recall}{{29}{15}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Considération comparative}{15}{}\protected@file@percent }
\newlabel{subsubsec:q3-comparative-consideration}{{\mbox  {V-C}}{15}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Q4: Analyse comparative avec des grands modèles de langage (LLMs)}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-A}}Méthodologie : Inférence générative}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-B}}Évaluation des performances}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VI-B}1}Résultats LLM (Gemma-3-4b-it)}{16}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Rapport de performance pour Gemma-3-4b-it (inférence few-shot). Le modèle montre une performance équilibrée mais modérée, avec une confusion notable entre les sentiments polarisés et la classe neutre.}}{16}{}\protected@file@percent }
\newlabel{fig:gemma_res}{{30}{16}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VI-B}2}Résultats basés sur BERT}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-C}}Discussion : Spécialisation vs. Généralisation}{16}{}\protected@file@percent }
\citation{b18}
\citation{b19}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Comparaison sur l’ensemble de test entre les 12 pipelines classiques (Q0--Q1) et les 16 modèles MLP (Q2). Les modèles sont classés par Macro-F1 (décroissant). Le meilleur global, le meilleur classique et le meilleur MLP sont mis en évidence en gras.}}{17}{}\protected@file@percent }
\newlabel{tab:q3-classical-vs-mlp}{{I}{17}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparaison directe : encodeur ajusté vs. LLM few-shot}}{17}{}\protected@file@percent }
\newlabel{tab:llm_vs_bert}{{II}{17}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Q5-Embeddings BERT vs. Représentations brutes}{17}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Rapport de performance pour la baseline BERT Linear Head.}}{18}{}\protected@file@percent }
\newlabel{fig:bert_best}{{31}{18}{}{}{}}
\newlabel{eq:param_count_fc}{{6}{18}{}{}{}}
\newlabel{eq:param_count_mlp_char}{{7}{18}{}{}{}}
\newlabel{eq:param_count_mlp_bert}{{8}{18}{}{}{}}
\citation{b_bert}
\citation{b_att}
\citation{b_bert}
\citation{b_bert}
\citation{b_bert}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Q6-Architecture de BERT et Cadre Théorique}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-A}}Architecture du modèle}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Différences dans les architectures de modèles de pré-entraînement. BERT utilise un Transformer bidirectionnel, ce qui le distingue d’OpenAI GPT et d’ELMo \cite  {b_bert}.}}{19}{}\protected@file@percent }
\newlabel{fig:bert_arch}{{32}{19}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}1}Auto-Attention multi-têtes}{19}{}\protected@file@percent }
\newlabel{eq:attention}{{9}{19}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}2}Réseau Feed-Forward et activation GELU}{19}{}\protected@file@percent }
\citation{b_bert}
\citation{b_bert}
\newlabel{eq:ffn}{{10}{20}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}3}Connexions résiduelles et normalisation}{20}{}\protected@file@percent }
\newlabel{eq:addnorm}{{11}{20}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-B}}Représentation d’entrée}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-B}1}Tokenisation WordPiece}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-B}2}Somme des embeddings}{20}{}\protected@file@percent }
\newlabel{eq:embeddings}{{12}{20}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Représentation d’entrée de BERT \cite  {b_bert}.}}{20}{}\protected@file@percent }
\newlabel{fig:bert_input}{{33}{20}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-C}}Objectifs de pré-entraînement}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-C}1}Modèle de langage masqué (MLM)}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-C}2}Prédiction de la phrase suivante (NSP)}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-D}}Stratégies d’application}{20}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Résultats de l’approche basée sur des caractéristiques sur CoNLL-2003 NER.}}{21}{}\protected@file@percent }
\newlabel{fig:bert_table}{{34}{21}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Q7-Ajustement fin avec LoRA pour la classification de sentiment}{21}{}\protected@file@percent }
\newlabel{sec:q7}{{IX}{21}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-A}}Aperçu de l’implémentation (pipeline notebook)}{21}{}\protected@file@percent }
\newlabel{subsec:q7-impl}{{\mbox  {IX-A}}{21}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-B}}Configuration LoRA (justification)}{21}{}\protected@file@percent }
\newlabel{subsec:q7-lora-params}{{\mbox  {IX-B}}{21}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Rapport d’évaluation complet pour \textbf  {BERT + LoRA (SEQ\_CLS)} sur l’ensemble de test (résumé des métriques, matrice de confusion et analyse ROC).}}{21}{}\protected@file@percent }
\newlabel{fig:q7-bert-lora-full-report}{{35}{21}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-C}}Résultats sur l’ensemble de test : BERT + LoRA (SEQ\_CLS)}{22}{}\protected@file@percent }
\newlabel{subsec:q7-results}{{\mbox  {IX-C}}{22}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-D}}Comparaison directe avec la baseline d’embeddings BERT (LinearHead 768$\rightarrow $3)}{22}{}\protected@file@percent }
\newlabel{subsec:q7-compare-bert-baseline}{{\mbox  {IX-D}}{22}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-E}}Positionnement du projet}{22}{}\protected@file@percent }
\newlabel{subsec:q7-positioning}{{\mbox  {IX-E}}{22}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {X}Conclusion}{22}{}\protected@file@percent }
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\bibcite{b10}{10}
\bibcite{b11}{11}
\bibcite{b12}{12}
\bibcite{b13}{13}
\bibcite{b14}{14}
\bibcite{b15}{15}
\bibcite{b16}{16}
\bibcite{b17}{17}
\bibcite{b18}{18}
\bibcite{b19}{19}
\bibcite{b_bert}{20}
\bibcite{b_att}{21}
\@writefile{toc}{\contentsline {section}{R\'ef\'erences}{23}{}\protected@file@percent }
\gdef \@abspage@last{23}
