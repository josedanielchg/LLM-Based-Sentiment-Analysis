\relax 
\citation{b1}
\citation{b2}
\citation{b3}
\citation{b4}
\citation{b5}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Q0-Dataset analysis with different classical machine learning model}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Exploratory data analysis (EDA)}{1}{}\protected@file@percent }
\citation{b5}
\citation{b5}
\citation{b6}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Distribution of sentiments in training dataset.\relax }}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:q0-eda}{{1}{2}}
\newlabel{eq:tfidf}{{1}{2}}
\newlabel{eq:idf}{{2}{2}}
\newlabel{eq:l2norm}{{3}{2}}
\newlabel{fig:q0-bow-uni}{{2a}{2}}
\newlabel{sub@fig:q0-bow-uni}{{(a)}{a}}
\newlabel{fig:q0-bow-bi}{{2b}{2}}
\newlabel{sub@fig:q0-bow-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Top 20 n-gramas with BoW.\relax }}{2}{}\protected@file@percent }
\newlabel{fig:q0-bow}{{2}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{2}{}\protected@file@percent }
\citation{b7}
\newlabel{fig:q0-tfidf-uni}{{3a}{3}}
\newlabel{sub@fig:q0-tfidf-uni}{{(a)}{a}}
\newlabel{fig:q0-tfidf-bi}{{3b}{3}}
\newlabel{sub@fig:q0-tfidf-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top 20 n-gramas with TF--IDF.\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-tfidf}{{3}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbu}{{4a}{3}}
\newlabel{sub@fig:q0-sbu}{{(a)}{a}}
\newlabel{fig:q0-sbtt}{{4b}{3}}
\newlabel{sub@fig:q0-sbtt}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparative sentiment distribution by category, stratified by user and tweet type\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbuubtt}{{4}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Sentiments by User}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Sentiments by type of tweet}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of sentiments in the top 10 countries.\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-dcountry}{{5}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Classic model training}{3}{}\protected@file@percent }
\citation{b8}
\citation{b9}
\citation{b11}
\citation{b12}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Word count distribution by sentiment\relax }}{4}{}\protected@file@percent }
\newlabel{fig:q0-wordcount}{{6}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Q1-Classification with Classical Models and Performance Analysis}{5}{}\protected@file@percent }
\newlabel{sec:q1}{{III}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Training time}{5}{}\protected@file@percent }
\newlabel{subsec:q1-time}{{\mbox  {III-A}}{5}}
\newlabel{subsubsec:q1-ttotal}{{\mbox  {III-A}1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}1}Total time estimate (sequential compute)}{5}{}\protected@file@percent }
\newlabel{eq:q1-e1}{{4}{5}}
\newlabel{subsubsec:q1-twall}{{\mbox  {III-A}2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}2}Wall-clock time with parallelization}{5}{}\protected@file@percent }
\newlabel{eq:q1-e2}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Test-set performance}{5}{}\protected@file@percent }
\newlabel{subsec:q1-test}{{\mbox  {III-B}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test comparison --- Macro-F1 (hue = vectorization).\relax }}{5}{}\protected@file@percent }
\newlabel{fig:q1-f1}{{7}{5}}
\newlabel{subsubsec:q1-vectorization}{{\mbox  {III-B}1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}1}Impact of the vectorization method}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Test comparison --- Macro-Recall (hue = vectorization).\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-f2}{{8}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Test comparison --- Accuracy (hue = vectorization).\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-f3}{{9}{6}}
\newlabel{subsubsec:q1-tradeoffs}{{\mbox  {III-B}2}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}2}Model comparison and trade-offs}{6}{}\protected@file@percent }
\newlabel{subsubsec:q1-cm}{{\mbox  {III-B}3}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}3}Confusion matrix analysis (TF--IDF char)}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Confusion matrix of \texttt  {best\_\_tfidf\_char\_\_svm}.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-cm-svm}{{10}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion matrix of \texttt  {best\_\_tfidf\_char\_\_lr}.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-cm-lr}{{11}{6}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3a}General pattern: the ``neutral'' class is the main source of ambiguity.}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3b}Good sign: low direct confusion between ``negative'' and ``positive''.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3c}Subtle differences between SVM and Logistic Regression.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Top-20 and Bottom-20 character n-grams per class (LR vs.\ SVM)}{7}{}\protected@file@percent }
\newlabel{subsec:q1-ngrams}{{\mbox  {III-C}}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Positive class}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Positive class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{7}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-top}{{12}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Positive class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{7}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-top}{{13}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Negative class}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Positive class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-bottom}{{14}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Positive class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-bottom}{{15}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Negative class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-top}{{16}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Negative class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-top}{{17}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Negative class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-bottom}{{18}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Negative class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-bottom}{{19}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Neutral class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-top}{{20}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Neutral class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-top}{{21}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}3}Neutral class}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Synthesis and practical considerations}{9}{}\protected@file@percent }
\newlabel{subsec:q1-synthesis}{{\mbox  {III-D}}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Neutral class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-bottom}{{22}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Neutral class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-bottom}{{23}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Q2-MLP Architectures for Short-Text Sentiment Classification}{9}{}\protected@file@percent }
\citation{b13}
\citation{b14}
\citation{b15}
\citation{b16}
\citation{b17}
\@writefile{toc}{\contentsline {section}{\numberline {V}Q3-Comparative Analysis of MLP Performance and Implications for Baseline Selection}{12}{}\protected@file@percent }
\newlabel{sec:q3}{{V}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Preliminary MLP performance analysis (Q2)}{13}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-prelim}{{\mbox  {V-A}}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces MLP test performance comparison --- Macro-F1 (hue = representation family).\relax }}{13}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-f1}{{24}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces MLP test performance comparison --- Macro-Recall (hue = representation family).\relax }}{13}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-recall}{{25}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces MLP test performance comparison --- Accuracy (hue = representation family).\relax }}{13}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-acc}{{26}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Comparison across MLP representation families (predictive quality)}{13}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-families}{{\mbox  {V-B}}{13}}
\newlabel{subsubsec:q3-char-tfidf}{{\mbox  {V-B}1}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}1}Char TF--IDF (best family in predictive quality)}{13}{}\protected@file@percent }
\newlabel{subsubsec:q3-bow-word}{{\mbox  {V-B}2}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}2}BoW and Word TF--IDF (intermediate performance, with BoW slightly higher)}{13}{}\protected@file@percent }
\newlabel{subsubsec:q3-bert}{{\mbox  {V-B}3}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}3}BERT (competitive, but not superior to Char TF--IDF under this regime)}{13}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces MLP training performance comparison --- Accuracy (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-acc}{{27}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces MLP training performance comparison --- Macro-F1 (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-f1}{{28}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces MLP training performance comparison --- Macro-Recall (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-recall}{{29}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Comparative consideration}{14}{}\protected@file@percent }
\newlabel{subsubsec:q3-comparative-consideration}{{\mbox  {V-C}}{14}}
\citation{b18}
\citation{b19}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Q5-Bert embeddings vs. Raw representations}{15}{}\protected@file@percent }
\newlabel{eq:param_count_fc}{{6}{15}}
\newlabel{eq:param_count_mlp_char}{{7}{15}}
\newlabel{eq:param_count_mlp_bert}{{8}{15}}
\citation{b_bert}
\citation{b_att}
\citation{b_bert}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Test-set comparison between the 12 classical pipelines (Q0--Q1) and the 16 MLP models (Q2). Models are ranked by Macro-F1 (descending). Best overall, best classical, and best MLP are highlighted in bold.\relax }}{16}{}\protected@file@percent }
\newlabel{tab:q3-classical-vs-mlp}{{I}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Q6-BERT Architecture and Theoretical Framework}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-A}}Model Architecture}{16}{}\protected@file@percent }
\citation{b_bert}
\citation{b_bert}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-A}1}Multi-Head Self-Attention}{17}{}\protected@file@percent }
\newlabel{eq:attention}{{9}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-A}2}Feed-Forward Network and GELU Activation}{17}{}\protected@file@percent }
\newlabel{eq:ffn}{{10}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-A}3}Residual Connections and Normalization}{17}{}\protected@file@percent }
\newlabel{eq:addnorm}{{11}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-B}}Input Representation}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-B}1}WordPiece Tokenization}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-B}2}Embedding Summation}{17}{}\protected@file@percent }
\newlabel{eq:embeddings}{{12}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces BERT input representation. The input embeddings are the sum of the token embeddings, the segmentation embeddings, and the position embeddings \cite  {b_bert}.\relax }}{17}{}\protected@file@percent }
\newlabel{fig:bert_input}{{30}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-C}}Pre-training Objectives}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-C}1}Masked Language Model (MLM)}{17}{}\protected@file@percent }
\citation{b_bert}
\citation{b_bert}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VII-C}2}Next Sentence Prediction (NSP)}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VII-D}}Application Strategies}{18}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Feature-based approach results on CoNLL-2003 NER. Concatenating the last 4 hidden layers yields performance comparable to fine-tuning \cite  {b_bert}.\relax }}{18}{}\protected@file@percent }
\newlabel{fig:bert_table}{{31}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Conclusion}{18}{}\protected@file@percent }
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\bibcite{b10}{10}
\bibcite{b11}{11}
\bibcite{b12}{12}
\bibcite{b13}{13}
\bibcite{b14}{14}
\bibcite{b15}{15}
\bibcite{b16}{16}
\bibcite{b17}{17}
\bibcite{b18}{18}
\bibcite{b19}{19}
\bibcite{b_bert}{20}
\bibcite{b_att}{21}
\@writefile{toc}{\contentsline {section}{References}{19}{}\protected@file@percent }
\gdef \@abspage@last{19}
