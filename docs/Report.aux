\relax 
\citation{b1}
\citation{b2}
\citation{b3}
\citation{b4}
\citation{b5}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Q0-Dataset analysis with different classical machine learning model}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Exploratory data analysis (EDA)}{1}{}\protected@file@percent }
\citation{b5}
\citation{b5}
\citation{b6}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Distribution of sentiments in training dataset.\relax }}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:q0-eda}{{1}{2}}
\newlabel{eq:tfidf}{{1}{2}}
\newlabel{eq:idf}{{2}{2}}
\newlabel{eq:l2norm}{{3}{2}}
\newlabel{fig:q0-bow-uni}{{2a}{2}}
\newlabel{sub@fig:q0-bow-uni}{{(a)}{a}}
\newlabel{fig:q0-bow-bi}{{2b}{2}}
\newlabel{sub@fig:q0-bow-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Top 20 n-gramas with BoW.\relax }}{2}{}\protected@file@percent }
\newlabel{fig:q0-bow}{{2}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{2}{}\protected@file@percent }
\citation{b7}
\newlabel{fig:q0-tfidf-uni}{{3a}{3}}
\newlabel{sub@fig:q0-tfidf-uni}{{(a)}{a}}
\newlabel{fig:q0-tfidf-bi}{{3b}{3}}
\newlabel{sub@fig:q0-tfidf-bi}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top 20 n-gramas with TF--IDF.\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-tfidf}{{3}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Monograms}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Bigrams}}}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbu}{{4a}{3}}
\newlabel{sub@fig:q0-sbu}{{(a)}{a}}
\newlabel{fig:q0-sbtt}{{4b}{3}}
\newlabel{sub@fig:q0-sbtt}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparative sentiment distribution by category, stratified by user and tweet type\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-sbuubtt}{{4}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Sentiments by User}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Sentiments by type of tweet}}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of sentiments in the top 10 countries.\relax }}{3}{}\protected@file@percent }
\newlabel{fig:q0-dcountry}{{5}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Classic model training}{3}{}\protected@file@percent }
\citation{b8}
\citation{b9}
\citation{b11}
\citation{b12}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Word count distribution by sentiment\relax }}{4}{}\protected@file@percent }
\newlabel{fig:q0-wordcount}{{6}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Q1-Classification with Classical Models and Performance Analysis}{5}{}\protected@file@percent }
\newlabel{sec:q1}{{III}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Training time}{5}{}\protected@file@percent }
\newlabel{subsec:q1-time}{{\mbox  {III-A}}{5}}
\newlabel{subsubsec:q1-ttotal}{{\mbox  {III-A}1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}1}Total time estimate (sequential compute)}{5}{}\protected@file@percent }
\newlabel{eq:q1-e1}{{4}{5}}
\newlabel{subsubsec:q1-twall}{{\mbox  {III-A}2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-A}2}Wall-clock time with parallelization}{5}{}\protected@file@percent }
\newlabel{eq:q1-e2}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Test-set performance}{5}{}\protected@file@percent }
\newlabel{subsec:q1-test}{{\mbox  {III-B}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test comparison --- Macro-F1 (hue = vectorization).\relax }}{5}{}\protected@file@percent }
\newlabel{fig:q1-f1}{{7}{5}}
\newlabel{subsubsec:q1-vectorization}{{\mbox  {III-B}1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}1}Impact of the vectorization method}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Test comparison --- Macro-Recall (hue = vectorization).\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-f2}{{8}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Test comparison --- Accuracy (hue = vectorization).\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-f3}{{9}{6}}
\newlabel{subsubsec:q1-tradeoffs}{{\mbox  {III-B}2}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}2}Model comparison and trade-offs}{6}{}\protected@file@percent }
\newlabel{subsubsec:q1-cm}{{\mbox  {III-B}3}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-B}3}Confusion matrix analysis (TF--IDF char)}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Confusion matrix of \texttt  {best\_\_tfidf\_char\_\_svm}.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-cm-svm}{{10}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion matrix of \texttt  {best\_\_tfidf\_char\_\_lr}.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:q1-cm-lr}{{11}{6}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3a}General pattern: the ``neutral'' class is the main source of ambiguity.}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3b}Good sign: low direct confusion between ``negative'' and ``positive''.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-B}3c}Subtle differences between SVM and Logistic Regression.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Top-20 and Bottom-20 character n-grams per class (LR vs.\ SVM)}{7}{}\protected@file@percent }
\newlabel{subsec:q1-ngrams}{{\mbox  {III-C}}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Positive class}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Positive class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{7}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-top}{{12}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Positive class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{7}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-top}{{13}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Negative class}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Positive class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-lr-bottom}{{14}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Positive class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-pos-svm-bottom}{{15}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Negative class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-top}{{16}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Negative class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-top}{{17}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Negative class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-lr-bottom}{{18}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Negative class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{8}{}\protected@file@percent }
\newlabel{fig:q1-neg-svm-bottom}{{19}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Neutral class: Top-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-top}{{20}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Neutral class: Top-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-top}{{21}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}3}Neutral class}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Synthesis and practical considerations}{9}{}\protected@file@percent }
\newlabel{subsec:q1-synthesis}{{\mbox  {III-D}}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Neutral class: Bottom-20 character n-grams (Logistic Regression) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-lr-bottom}{{22}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Neutral class: Bottom-20 character n-grams (Linear SVM) under TF--IDF char (\texttt  {char\_wb}).\relax }}{9}{}\protected@file@percent }
\newlabel{fig:q1-neu-svm-bottom}{{23}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Q2-MLP Architectures for Short-Text Sentiment Classification}{9}{}\protected@file@percent }
\citation{b13}
\citation{b14}
\citation{b15}
\citation{b16}
\citation{b17}
\@writefile{toc}{\contentsline {section}{\numberline {V}Q4: Comparative Analysis with Large Language Models (LLMs)}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Methodology: Generative Inference}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Performance Evaluation}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}1}LLM Results (Gemma-3-4b-it)}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {V-B}2}BERT-based Results}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Discussion: Specialization vs. Generalization}{13}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Head-to-Head: Fine-Tuned Encoder vs. Few-Shot LLM\relax }}{13}{}\protected@file@percent }
\newlabel{tab:llm_vs_bert}{{I}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Performance Report for Gemma-3-4b-it (Few-Shot Inference). The model shows a balanced but moderate performance, with notable confusion between polarized sentiments and the neutral class.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:gemma_res}{{24}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Q3-Comparative Analysis of MLP Performance and Implications for Baseline Selection}{13}{}\protected@file@percent }
\newlabel{sec:q3}{{VI}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Performance Report for the BERT Linear Head Baseline.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:bert_best}{{25}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-A}}Preliminary MLP performance analysis (Q2)}{14}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-prelim}{{\mbox  {VI-A}}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces MLP test performance comparison --- Macro-F1 (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-f1}{{26}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces MLP test performance comparison --- Macro-Recall (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-recall}{{27}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces MLP test performance comparison --- Accuracy (hue = representation family).\relax }}{14}{}\protected@file@percent }
\newlabel{fig:q3-mlp-test-acc}{{28}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-B}}Comparison across MLP representation families (predictive quality)}{14}{}\protected@file@percent }
\newlabel{subsec:q3-mlp-families}{{\mbox  {VI-B}}{14}}
\newlabel{subsubsec:q3-char-tfidf}{{\mbox  {VI-B}1}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VI-B}1}Char TF--IDF (best family in predictive quality)}{15}{}\protected@file@percent }
\newlabel{subsubsec:q3-bow-word}{{\mbox  {VI-B}2}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VI-B}2}BoW and Word TF--IDF (intermediate performance, with BoW slightly higher)}{15}{}\protected@file@percent }
\newlabel{subsubsec:q3-bert}{{\mbox  {VI-B}3}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VI-B}3}BERT (competitive, but not superior to Char TF--IDF under this regime)}{15}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces MLP training performance comparison --- Accuracy (hue = representation family).\relax }}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-acc}{{29}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces MLP training performance comparison --- Macro-F1 (hue = representation family).\relax }}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-f1}{{30}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces MLP training performance comparison --- Macro-Recall (hue = representation family).\relax }}{15}{}\protected@file@percent }
\newlabel{fig:q3-mlp-train-recall}{{31}{15}}
\citation{b18}
\citation{b19}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-C}}Comparative consideration}{16}{}\protected@file@percent }
\newlabel{subsubsec:q3-comparative-consideration}{{\mbox  {VI-C}}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Q5-Bert embeddings vs. Raw representations}{16}{}\protected@file@percent }
\newlabel{eq:param_count_fc}{{6}{16}}
\newlabel{eq:param_count_mlp_char}{{7}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Test-set comparison between the 12 classical pipelines (Q0--Q1) and the 16 MLP models (Q2). Models are ranked by Macro-F1 (descending). Best overall, best classical, and best MLP are highlighted in bold.\relax }}{17}{}\protected@file@percent }
\newlabel{tab:q3-classical-vs-mlp}{{II}{17}}
\newlabel{eq:param_count_mlp_bert}{{8}{17}}
\citation{b_bert}
\citation{b_att}
\citation{b_bert}
\citation{b_bert}
\citation{b_bert}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Q6-BERT Architecture and Theoretical Framework}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-A}}Model Architecture}{18}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Differences in pre-training model architectures. BERT uses a bidirectional Transformer, distinguishing it from OpenAI GPT and ELMo \cite  {b_bert}.\relax }}{18}{}\protected@file@percent }
\newlabel{fig:bert_arch}{{32}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}1}Multi-Head Self-Attention}{18}{}\protected@file@percent }
\newlabel{eq:attention}{{9}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}2}Feed-Forward Network and GELU Activation}{18}{}\protected@file@percent }
\newlabel{eq:ffn}{{10}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-A}3}Residual Connections and Normalization}{18}{}\protected@file@percent }
\newlabel{eq:addnorm}{{11}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-B}}Input Representation}{18}{}\protected@file@percent }
\citation{b_bert}
\citation{b_bert}
\citation{b_bert}
\citation{b_bert}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-B}1}WordPiece Tokenization}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-B}2}Embedding Summation}{19}{}\protected@file@percent }
\newlabel{eq:embeddings}{{12}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces BERT input representation. The input embeddings are the sum of the token embeddings, the segmentation embeddings, and the position embeddings \cite  {b_bert}.\relax }}{19}{}\protected@file@percent }
\newlabel{fig:bert_input}{{33}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-C}}Pre-training Objectives}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-C}1}Masked Language Model (MLM)}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {VIII-C}2}Next Sentence Prediction (NSP)}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VIII-D}}Application Strategies}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Feature-based approach results on CoNLL-2003 NER. Concatenating the last 4 hidden layers yields performance comparable to fine-tuning \cite  {b_bert}.\relax }}{19}{}\protected@file@percent }
\newlabel{fig:bert_table}{{34}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Q7-Fine-Tuning with LoRA for Sentiment Classification}{19}{}\protected@file@percent }
\newlabel{sec:q7}{{IX}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-A}}Implementation overview (notebook pipeline)}{19}{}\protected@file@percent }
\newlabel{subsec:q7-impl}{{\mbox  {IX-A}}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Full evaluation report for \textbf  {BERT + LoRA (SEQ\_CLS)} on the test set (metrics summary, confusion matrix, and ROC analysis).\relax }}{20}{}\protected@file@percent }
\newlabel{fig:q7-bert-lora-full-report}{{35}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-B}}LoRA configuration (rationale)}{20}{}\protected@file@percent }
\newlabel{subsec:q7-lora-params}{{\mbox  {IX-B}}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-C}}Test-set results: BERT + LoRA (SEQ\_CLS)}{20}{}\protected@file@percent }
\newlabel{subsec:q7-results}{{\mbox  {IX-C}}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-D}}Direct comparison with the BERT embedding baseline (LinearHead 768$\rightarrow $3)}{20}{}\protected@file@percent }
\newlabel{subsec:q7-compare-bert-baseline}{{\mbox  {IX-D}}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IX-E}}Project positioning}{20}{}\protected@file@percent }
\newlabel{subsec:q7-positioning}{{\mbox  {IX-E}}{20}}
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\@writefile{toc}{\contentsline {section}{\numberline {X}Conclusion}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{21}{}\protected@file@percent }
\bibcite{b10}{10}
\bibcite{b11}{11}
\bibcite{b12}{12}
\bibcite{b13}{13}
\bibcite{b14}{14}
\bibcite{b15}{15}
\bibcite{b16}{16}
\bibcite{b17}{17}
\bibcite{b18}{18}
\bibcite{b19}{19}
\bibcite{b_bert}{20}
\bibcite{b_att}{21}
\gdef \@abspage@last{22}
